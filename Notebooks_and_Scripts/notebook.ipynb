import pandas as pd
import numpy as np
import lightgbm as lgb
from sklearn.preprocessing import LabelEncoder
import gc
import warnings
import time

start_time = time.time()

# --- Configuration ---
DATA_PATH = '/kaggle/input/data-crunch-round-1/'
TRAIN_FILE = DATA_PATH + 'train.csv'
TEST_FILE = DATA_PATH + 'test.csv'
SAMPLE_SUB_FILE = DATA_PATH + 'sample_submission.csv'
OUTPUT_FILE = 'submission.csv'

TARGET_COLS_ORIGINAL = [
    'Avg_Temperature', 'Radiation', 'Rain_Amount', 'Wind_Speed', 'Wind_Direction'
]

FEATURE_COLS_FOR_ENGINEERING = [
    'Avg_Temperature', 'Radiation', 'Rain_Amount', 'Wind_Speed', 'Wind_Direction',
    'Avg_Feels_Like_Temperature', 'Evapotranspiration', 'Rain_Duration',
    'Temperature_Range', 'Feels_Like_Temperature_Range'
]
LAGS = [1, 3, 7, 14, 21, 30, 60]
ROLLING_WINDOWS = [3, 7, 14, 30, 60]

# --- Helper Functions ---
def smape(y_true, y_pred):
    """Symmetric Mean Absolute Percentage Error"""
    numerator = np.abs(y_pred - y_true)
    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2
    epsilon = 1e-9
    ratio = np.where(denominator < epsilon, 0, numerator / denominator)
    return np.mean(ratio) * 100

def kelvin_to_celsius(temp_k):
    """Converts Kelvin to Celsius"""
    return temp_k - 273.15

def create_features(df):
    """Create time-based and engineered features"""
    script_start_time = time.time()
    print("Starting feature creation...")

    print("  Coercing Year, Month, Day to numeric...")
    for col in ['Year', 'Month', 'Day']:
        df[col] = pd.to_numeric(df[col], errors='coerce')
        df[col] = df[col].astype(pd.Int64Dtype())

    print("  Creating placeholder datetime...")
    base_year = 2000
    valid_year_idx = df['Year'].notna()
    df.loc[valid_year_idx, 'temp_year_calc'] = base_year + df.loc[valid_year_idx, 'Year'] - 1
    temp_df_for_datetime = pd.DataFrame({
        'year': pd.Series(df['temp_year_calc']),
        'month': pd.Series(df['Month']),
        'day': pd.Series(df['Day'])
    })
    df['datetime'] = pd.to_datetime(temp_df_for_datetime, errors='coerce')
    df = df.drop(columns=['temp_year_calc'], errors='ignore')
    if df['datetime'].isnull().any():
        print(f"  Warning: {df['datetime'].isnull().sum()} NaT values created in datetime.")

    print("  Calculating time features...")
    df['dayofyear'] = df['datetime'].dt.dayofyear.astype(pd.Int64Dtype())
    df['dayofweek'] = df['datetime'].dt.dayofweek.astype(pd.Int64Dtype())
    df['month'] = df['Month']
    df['weekofyear'] = df['datetime'].dt.isocalendar().week.astype(pd.Int64Dtype())
    df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)
    df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)
    df['dayofyear_sin'] = np.sin(2 * np.pi * df['dayofyear'] / 365.25)
    df['dayofyear_cos'] = np.cos(2 * np.pi * df['dayofyear'] / 365.25)

    print("  Sorting data...")
    df = df.sort_values(by=['kingdom', 'datetime'], na_position='first').reset_index(drop=True)

    print("  Creating lag/rolling features...")
    with warnings.catch_warnings():
        warnings.simplefilter("ignore", category=pd.errors.PerformanceWarning)
        for col in FEATURE_COLS_FOR_ENGINEERING:
            if col in df.columns and pd.api.types.is_numeric_dtype(df[col]):
                print(f"    Processing: {col}")
                df_col = df.groupby('kingdom')[col]
                shifted = df_col.shift(1)
                for lag in LAGS:
                    df[f'{col}_lag_{lag}'] = df_col.shift(lag)
                for window in ROLLING_WINDOWS:
                    base_name = f'{col}_roll_{window}'
                    rolling_obj = shifted.rolling(window=window, min_periods=max(1, window // 2))
                    df[f'{base_name}_mean'] = rolling_obj.mean()
                    df[f'{base_name}_std'] = rolling_obj.std()
                    df[f'{base_name}_median'] = rolling_obj.median()
                    df[f'{base_name}_min'] = rolling_obj.min()
                    df[f'{base_name}_max'] = rolling_obj.max()
                del shifted, df_col; gc.collect()
            elif col in df.columns:
                print(f"    Skipping non-numeric column: {col}")

        print("  Creating lag difference features...")
        for col in FEATURE_COLS_FOR_ENGINEERING:
             if col in df.columns and pd.api.types.is_numeric_dtype(df[col]):
                 lag1 = df.get(f'{col}_lag_1')
                 lag7 = df.get(f'{col}_lag_7')
                 lag30 = df.get(f'{col}_lag_30')
                 if lag1 is not None and lag7 is not None:
                     df[f'{col}_lag_1_diff_7'] = lag1 - lag7
                 if lag7 is not None and lag30 is not None:
                     df[f'{col}_lag_7_diff_30'] = lag7 - lag30

    print("Creating sin/cos features for Wind_Direction...")
    if 'Wind_Direction' in df.columns and pd.api.types.is_numeric_dtype(df['Wind_Direction']):
        valid_wd_idx = df['Wind_Direction'].notna()
        radians = np.deg2rad(df.loc[valid_wd_idx, 'Wind_Direction'])
        df['Wind_Direction_sin'] = np.nan
        df['Wind_Direction_cos'] = np.nan
        df.loc[valid_wd_idx, 'Wind_Direction_sin'] = np.sin(radians)
        df.loc[valid_wd_idx, 'Wind_Direction_cos'] = np.cos(radians)
        print("Created Wind_Direction_sin and Wind_Direction_cos")
    else:
        print("Wind_Direction column not found/numeric, skipping sin/cos.")

    print("Defragmenting DataFrame...")
    df = df.copy()
    gc.collect()
    print(f"Feature creation finished. Took {time.time() - script_start_time:.2f} seconds.")
    return df

# --- Model Parameters ---
best_params_all_targets = {
    'Avg_Temperature': {'n_estimators': 1900, 'learning_rate': 0.0828128689475584, 'num_leaves': 39, 'lambda_l1': 8.750689764462542e-05, 'lambda_l2': 3.93275189240028e-05, 'feature_fraction': 0.9890231216201054, 'bagging_fraction': 0.7459183833074896, 'bagging_freq': 7, 'min_child_samples': 31},
    'Radiation': {'n_estimators': 2800, 'learning_rate': 0.08956222974984081, 'num_leaves': 57, 'lambda_l1': 0.0008960599433071907, 'lambda_l2': 1.8201280565840412e-06, 'feature_fraction': 0.5240160851989188, 'bagging_fraction': 0.9707406766511902, 'bagging_freq': 7, 'min_child_samples': 9},
    'Rain_Amount': {'n_estimators': 2700, 'learning_rate': 0.05103340014737211, 'num_leaves': 58, 'lambda_l1': 0.0025182729657402397, 'lambda_l2': 0.002973823781791273, 'feature_fraction': 0.9399075201882323, 'bagging_fraction': 0.8035248983116494, 'bagging_freq': 3, 'min_child_samples': 53},
    'Wind_Speed': {'n_estimators': 2900, 'learning_rate': 0.07831440628654988, 'num_leaves': 57, 'lambda_l1': 0.00015647344185333698, 'lambda_l2': 0.38472028866963404, 'feature_fraction': 0.5763391897615601, 'bagging_fraction': 0.9290802446572453, 'bagging_freq': 7, 'min_child_samples': 24},
    'Wind_Direction_sin': {'n_estimators': 2400, 'learning_rate': 0.06902085344455576, 'num_leaves': 57, 'lambda_l1': 0.00040524998041614247, 'lambda_l2': 0.001649496287281898, 'feature_fraction': 0.9920034571118559, 'bagging_fraction': 0.8809290260521517, 'bagging_freq': 5, 'min_child_samples': 18},
    'Wind_Direction_cos': {'n_estimators': 3000, 'learning_rate': 0.08566941408355047, 'num_leaves': 54, 'lambda_l1': 1.0956539954233748, 'lambda_l2': 0.8981181634918208, 'feature_fraction': 0.9964466174073006, 'bagging_fraction': 0.9957888418801415, 'bagging_freq': 5, 'min_child_samples': 30}
}

default_lgb_params = {
    'objective': 'regression_l1', 'metric': 'mae', 'n_estimators': 1500,
    'learning_rate': 0.05, 'feature_fraction': 0.8, 'bagging_fraction': 0.8,
    'bagging_freq': 1, 'lambda_l1': 0.1, 'lambda_l2': 0.1,
    'num_leaves': 31, 'verbose': -1, 'n_jobs': -1, 'seed': 42,
    'boosting_type': 'gbdt',
}

# --- Data Loading and Preprocessing ---
print("Loading data...")
train_df_orig = pd.read_csv(TRAIN_FILE)
test_df_orig = pd.read_csv(TEST_FILE)
sample_sub = pd.read_csv(SAMPLE_SUB_FILE)

print("Preprocessing base data...")
test_df_orig['is_test'] = 1
train_df_orig['is_test'] = 0
targets_for_nan = TARGET_COLS_ORIGINAL
for col in targets_for_nan:
    if col not in test_df_orig.columns: test_df_orig[col] = np.nan
for col in train_df_orig.columns:
    if col not in test_df_orig.columns and col not in ['ID', 'is_test']: test_df_orig[col] = np.nan
df = pd.concat([train_df_orig, test_df_orig], ignore_index=True, sort=False)
del train_df_orig, test_df_orig; gc.collect()

# --- Location Mapping ---
print("Mapping lat/lon...")
coord_map = df[df['is_test'] == 0].groupby('kingdom')[['latitude', 'longitude']].first().reset_index()
df = pd.merge(df.drop(['latitude', 'longitude'], axis=1, errors='ignore'), coord_map, on='kingdom', how='left')
if df['latitude'].isnull().any(): print("Warning: Missing lat/lon coords in test.")

# --- Temperature Conversion ---
print("Converting temperatures...")
temp_cols = ['Avg_Temperature', 'Avg_Feels_Like_Temperature']
for col in temp_cols:
    if col in df.columns:
         mask = (df[col] > 70) & (~df[col].isnull())
         df.loc[mask, col] = df.loc[mask, col].apply(kelvin_to_celsius)

# --- Feature Engineering ---
df = create_features(df)

# --- Label Encoding ---
print("Label encoding kingdom...")
le = LabelEncoder()
df['kingdom_encoded'] = le.fit_transform(df['kingdom'])

# --- Feature Selection ---
features_to_exclude = TARGET_COLS_ORIGINAL + ['Wind_Direction_sin', 'Wind_Direction_cos',
                     'ID', 'Year', 'Month', 'Day', 'kingdom', 'is_test', 'datetime'] + \
                    ['Avg_Feels_Like_Temperature','Evapotranspiration', 'Rain_Duration',
                     'Temperature_Range', 'Feels_Like_Temperature_Range']
basic_time_features = ['month_sin', 'month_cos', 'dayofyear_sin', 'dayofyear_cos']

features = sorted([f for f in df.columns if f not in features_to_exclude])
print(f"\nUsing {len(features)} features for modeling.")

# --- Train/Test Split ---
print("Splitting data...")
df_train = df[df['is_test'] == 0]
df_test = df[df['is_test'] == 1]
X_test_full = df_test[features]
test_ids = df_test['ID']

del df; gc.collect()

# --- Model Training and Prediction ---
predictions = pd.DataFrame({'ID': test_ids})
targets_to_predict = ['Avg_Temperature', 'Radiation', 'Rain_Amount', 'Wind_Speed', 'Wind_Direction_sin', 'Wind_Direction_cos']

for target in targets_to_predict:
    print(f"\n--- Training FINAL model for: {target} ---")

    # Prepare full training data
    X_train_full = df_train[features]
    y_train_full = df_train[target]
    valid_train_idx = y_train_full.dropna().index
    X_train_target = X_train_full.loc[valid_train_idx]
    y_train_target = y_train_full.loc[valid_train_idx]

    if X_train_target.empty:
         print(f"Skipping {target} - no valid training data.")
         predictions[target] = 0
         continue

    # Get parameters for this target
    if target in best_params_all_targets:
        print(f"Using tuned parameters for {target}")
        tuned_params = best_params_all_targets[target]
    else:
        print(f"Warning: Tuned params not found for {target}. Using defaults.")
        tuned_params = {}

    # Define final parameters
    final_lgb_params = default_lgb_params.copy()
    final_lgb_params.update(tuned_params)
    final_lgb_params['objective'] = 'regression_l1'
    if 'tweedie_variance_power' in final_lgb_params:
        del final_lgb_params['tweedie_variance_power']

    if 'n_estimators' not in final_lgb_params or final_lgb_params['n_estimators'] is None:
        print("Warning: n_estimators invalid! Setting default.")
        final_lgb_params['n_estimators'] = default_lgb_params['n_estimators']
    final_lgb_params['seed'] = 42

    print(f"Final params for {target}: {final_lgb_params}")
    model = lgb.LGBMRegressor(**final_lgb_params)

    # Fit model and predict
    model.fit(X_train_target, y_train_target)
    target_preds = model.predict(X_test_full)
    predictions[target] = target_preds
    print(f"Finished predicting for {target}")
    del X_train_target, y_train_target, model; gc.collect()

# --- Post-processing ---
print("Combining sin/cos predictions for Wind_Direction...")
pred_sin = predictions['Wind_Direction_sin']
pred_cos = predictions['Wind_Direction_cos']
angle_rad = np.arctan2(pred_sin, pred_cos)
angle_deg = np.rad2deg(angle_rad)
final_wind_direction_preds = angle_deg % 360
predictions['Wind_Direction'] = final_wind_direction_preds

# --- Final Submission Preparation ---
final_prediction_columns = ['ID'] + TARGET_COLS_ORIGINAL
predictions_final = predictions[final_prediction_columns].copy()

print("Clipping negative predictions...")
for col in ['Radiation', 'Rain_Amount', 'Wind_Speed']:
    if col in predictions_final.columns:
        predictions_final[col] = np.maximum(0, predictions_final[col])

print("\nGenerating submission file...")
final_submission = sample_sub[['ID']].merge(predictions_final, on='ID', how='left')

if final_submission.isnull().any().any():
    print("Warning: NaNs found in final submission! Filling with 0.")
    final_submission.fillna(0, inplace=True)

final_submission.to_csv(OUTPUT_FILE, index=False)
print(f"Submission file saved to: {OUTPUT_FILE}")
print(f"Total script runtime: {time.time() - start_time:.2f} seconds")
print("Script finished.")
